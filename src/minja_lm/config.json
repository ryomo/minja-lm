{
  "architectures": [
    "MinjaLM"
  ],
  "block_size": 16,
  "model_type": "minja-lm",
  "n_embd": 128,
  "n_head": 2,
  "n_layer": 2,
  "torch_dtype": "float32",
  "transformers_version": "4.52.4",
  "vocab_size": 32000
}
